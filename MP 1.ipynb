{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x_test', 'x_train', 'y_test', 'y_train']\n"
     ]
    }
   ],
   "source": [
    "### I have manipulated the example code that is given in the lecture note in IE 498 / CS 547 \n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import time\n",
    "import copy\n",
    "from random import randint\n",
    "#load MNIST data\n",
    "MNIST_data = h5py.File('MNISTdata_1.hdf5', 'r')\n",
    "print(list(MNIST_data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.float32(MNIST_data['x_train'][:] )\n",
    "y_train = np.int32(np.array(MNIST_data['y_train'][:,0])) \n",
    "x_test = np.float32( MNIST_data['x_test'][:] )\n",
    "y_test = np.int32( np.array( MNIST_data['y_test'][:,0] ) )\n",
    "MNIST_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training in process.. ( 1 / 20 )\n",
      "Accuracy is 87.62333333333333 %\n",
      "training in process.. ( 2 / 20 )\n",
      "Accuracy is 94.10833333333333 %\n",
      "training in process.. ( 3 / 20 )\n",
      "Accuracy is 95.45333333333333 %\n",
      "training in process.. ( 4 / 20 )\n",
      "Accuracy is 96.35000000000001 %\n",
      "training in process.. ( 5 / 20 )\n",
      "Accuracy is 97.02333333333333 %\n",
      "training in process.. ( 6 / 20 )\n",
      "Accuracy is 97.555 %\n",
      "training in process.. ( 7 / 20 )\n",
      "Accuracy is 97.84333333333333 %\n",
      "training in process.. ( 8 / 20 )\n",
      "Accuracy is 98.04 %\n",
      "training in process.. ( 9 / 20 )\n",
      "Accuracy is 97.94166666666668 %\n",
      "training in process.. ( 10 / 20 )\n",
      "Accuracy is 98.1 %\n",
      "training in process.. ( 11 / 20 )\n",
      "Accuracy is 98.11833333333333 %\n",
      "training in process.. ( 12 / 20 )\n",
      "Accuracy is 98.165 %\n",
      "training in process.. ( 13 / 20 )\n",
      "Accuracy is 98.08666666666667 %\n",
      "training in process.. ( 14 / 20 )\n",
      "Accuracy is 98.03666666666668 %\n",
      "training in process.. ( 15 / 20 )\n",
      "Accuracy is 98.055 %\n",
      "training in process.. ( 16 / 20 )\n",
      "Accuracy is 98.13499999999999 %\n",
      "training in process.. ( 17 / 20 )\n",
      "Accuracy is 98.17666666666666 %\n",
      "training in process.. ( 18 / 20 )\n",
      "Accuracy is 98.16833333333334 %\n",
      "training in process.. ( 19 / 20 )\n",
      "Accuracy is 98.07000000000001 %\n",
      "training in process.. ( 20 / 20 )\n",
      "Accuracy is 98.095 %\n",
      "Processing time was 412.1011600494385\n",
      "Test Result:  0.9733 %\n"
     ]
    }
   ],
   "source": [
    "####################################################################################\n",
    "#Implementation of stochastic gradient descent algorithm\n",
    "\n",
    "\n",
    "#number of inputs\n",
    "d = 28*28\n",
    "#number of outputs\n",
    "k = 10\n",
    "#dim of hiddenlayer\n",
    "dh = 100\n",
    "\n",
    "#Randomly create array with certain dimension\n",
    "model = {}\n",
    "model['W'] = np.random.randn(dh,d) / np.sqrt(d) \n",
    "model['CT'] = np.random.randn(k,dh) / np.sqrt(d)\n",
    "model['b1'] = np.zeros((dh,1))\n",
    "model['b2'] = np.zeros((k,1))\n",
    "\n",
    "#make a copy for later to implement\n",
    "model_grads = copy.deepcopy(model)\n",
    "\n",
    "#define functions for SGD\n",
    "def softmax_function(z):\n",
    "    ZZ = np.exp(z)/np.sum(np.exp(z)) \n",
    "    return ZZ\n",
    "\n",
    "def sigmoid(z):\n",
    "    return np.exp(z)/(1+np.exp(z))\n",
    "\n",
    "def forward(x,y, model):\n",
    "    x = x.reshape((784,1))\n",
    "    Z = np.dot(model['W'], x) + model['b1']\n",
    "    H = sigmoid(Z)\n",
    "    U = np.dot(model['CT'], H) + model['b2']\n",
    "    f = softmax_function(U)\n",
    "    model['H'] = H\n",
    "    model['Z'] = Z\n",
    "    model['U'] = U\n",
    "    model['p'] = f\n",
    "    return f\n",
    "\n",
    "def sigmoidprime(z):\n",
    "    sprime = 1/(1+np.exp(-z))\n",
    "    return sprime * (1-sprime)\n",
    "\n",
    "def backward(x,y,p, model, model_grads): \n",
    "    dpdU = -1.0*p\n",
    "    dpdU[y] = dpdU[y] + 1.0\n",
    "    dpdb2 = dpdU\n",
    "    dpdC = np.dot(dpdU,model['H'].T)\n",
    "    delta = np.dot(model['CT'].T,dpdU)\n",
    "    sigprime = sigmoidprime(model['Z'])\n",
    "    dpdb1 = np.multiply(delta, sigprime)\n",
    "    dpdW = np.dot(dpdb1,x.reshape(1,784))\n",
    "    model_grads['W'] = dpdW\n",
    "    model_grads['CT'] = dpdC\n",
    "    model_grads['b1'] = dpdb1\n",
    "    model_grads['b2'] = dpdb2\n",
    "    return model_grads\n",
    "\n",
    "#### train the model\n",
    "\n",
    "import time\n",
    "time1 = time.time() \n",
    "LR = .01\n",
    "num_epochs = 20\n",
    "for epochs in range(num_epochs):\n",
    "    #Learning rate schedule\n",
    "    if (epochs > 5): \n",
    "        LR = 0.001\n",
    "    if (epochs > 10): \n",
    "        LR = 0.0001\n",
    "    if (epochs > 15): \n",
    "        LR = 0.00001\n",
    "        \n",
    "    total_correct = 0   \n",
    "    for n in range(len(x_train)):\n",
    "        n_random = randint(0,len(x_train)-1 ) \n",
    "        y = y_train[n_random]\n",
    "        x = x_train[n_random][:]\n",
    "        p = forward(x, y, model)\n",
    "        prediction = np.argmax(p)\n",
    "        if (prediction == y):\n",
    "            total_correct += 1\n",
    "        model_grads = backward(x,y,p, model, model_grads)\n",
    "        model['W'] = model['W'] + LR*model_grads['W']\n",
    "        model['CT'] = model['CT'] + LR*model_grads['CT']\n",
    "        model['b1'] = model['b1'] + LR*model_grads['b1']\n",
    "        model['b2'] = model['b2'] + LR*model_grads['b2']\n",
    "    print(\"training in process..\", \"(\",epochs+1,\"/\",num_epochs,\")\")\n",
    "    print(\"Accuracy is\",(total_correct/np.float(len(x_train)))*100,\"%\") \n",
    "    \n",
    "time2 = time.time()\n",
    "print(\"Processing time was\", time2-time1)\n",
    "###################################################### #test data\n",
    "total_correct = 0\n",
    "for n in range( len(x_test)):\n",
    "    y = y_test[n]\n",
    "    x = x_test[n][:]\n",
    "    p = forward(x, y, model)\n",
    "    prediction = np.argmax(p) \n",
    "    if (prediction == y):\n",
    "        total_correct += 1 \n",
    "        \n",
    "print(\"Test Result: \",total_correct/np.float(len(x_test)), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
